{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Competition Description from Kaggle:</b>\n",
    "\n",
    "Think back to your favorite teacher. They motivated and inspired you to learn. And they knew your strengths and weaknesses. The lessons they taught were based on your ability. For example, teachers would make sure you understood algebra before advancing to calculus. Yet, many students don’t have access to personalized learning. In a world full of information, data scientists like you can help. Machine learning can offer a path to success for young people around the world, and you are invited to be part of this mission.\n",
    "\n",
    "\n",
    "\n",
    "In 2018, 260 million children weren't attending school. At the same time, more than half of these young students didn't meet minimum reading and math standards. Education was already in a tough place when COVID-19 forced most countries to temporarily close schools. This further delayed learning opportunities and intellectual development. The equity gaps in every country could grow wider. We need to re-think the current education system in terms of attendance, engagement, and individualized attention.\n",
    "\n",
    "Riiid Labs, an AI solutions provider delivering creative disruption to the education market, empowers global education players to rethink traditional ways of learning leveraging AI. With a strong belief in equal opportunity in education, Riiid launched an AI tutor based on deep-learning algorithms in 2017 that attracted more than one million South Korean students. This year, the company released EdNet, the world’s largest open database for AI education containing more than 100 million student interactions.\n",
    "\n",
    "In this competition, your challenge is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time. The goal is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid’s EdNet data.\n",
    "\n",
    "Your innovative algorithms will help tackle global challenges in education. If successful, it’s possible that any student with an Internet connection can enjoy the benefits of a personalized learning experience, regardless of where they live. With your participation, we can build a better and more equitable model for education in a post-COVID-19 world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:58:28.710668Z",
     "start_time": "2020-11-17T21:58:28.704669Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:58:30.557404Z",
     "start_time": "2020-11-17T21:58:29.380603Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 56328 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster) # start a local Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:58:32.731604Z",
     "start_time": "2020-11-17T21:58:32.678594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc88f8451994544a6802f659e9508eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>LocalCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the competition data from kaggle\n",
    "# ! kaggle competitions download -c riiid-test-answer-prediction -p ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "# with zipfile.ZipFile('../../data/riiid-test-answer-prediction.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:59:52.558676Z",
     "start_time": "2020-11-17T21:58:36.890824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the data as Pandas DataFrames\n",
    "train = pd.read_csv('../../data/train.csv')\n",
    "questions = pd.read_csv('../../data/questions.csv')\n",
    "lectures = pd.read_csv('../../data/lectures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:11:51.761981Z",
     "start_time": "2020-11-17T21:11:51.748979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101230332, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "# 101,230,332 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:11:51.807978Z",
     "start_time": "2020-11-17T21:11:51.767980Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101230332 entries, 0 to 101230331\n",
      "Data columns (total 10 columns):\n",
      "row_id                            int64\n",
      "timestamp                         int64\n",
      "user_id                           int64\n",
      "content_id                        int64\n",
      "content_type_id                   int64\n",
      "task_container_id                 int64\n",
      "user_answer                       int64\n",
      "answered_correctly                int64\n",
      "prior_question_elapsed_time       float64\n",
      "prior_question_had_explanation    object\n",
      "dtypes: float64(1), int64(8), object(1)\n",
      "memory usage: 7.5+ GB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:11:51.839978Z",
     "start_time": "2020-11-17T21:11:51.809978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0       0          0      115        5692                0                  1   \n",
       "1       1      56943      115        5716                0                  2   \n",
       "2       2     118363      115         128                0                  0   \n",
       "3       3     131167      115        7860                0                  3   \n",
       "4       4     137965      115        7922                0                  4   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            3                   1                          NaN   \n",
       "1            2                   1                      37000.0   \n",
       "2            0                   1                      55000.0   \n",
       "3            0                   1                      19000.0   \n",
       "4            1                   1                      11000.0   \n",
       "\n",
       "  prior_question_had_explanation  \n",
       "0                            NaN  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:59:55.755625Z",
     "start_time": "2020-11-17T21:59:52.566677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "X = train.drop('answered_correctly', axis=1)\n",
    "y = train['answered_correctly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T21:11:49.088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class Imbalance\n",
    "sns.set(context = 'notebook', style = 'whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (10,4)) \n",
    "ax.hist(y, color = 'red', alpha = .5, bins = 5)\n",
    "ax.set_title('Class distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:01:06.880012Z",
     "start_time": "2020-11-17T21:59:55.760625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Test Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:01:23.905384Z",
     "start_time": "2020-11-17T22:01:06.941796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline for preprocessing numeric features\n",
    "numeric_features = list(X.select_dtypes(exclude='object').columns)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline for preprocessing categorical features\n",
    "categorical_features = list(X.select_dtypes(include='object').columns)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(fill_value=False)),\n",
    "    ('one_hot_encoder', OneHotEncoder(sparse=False))])\n",
    "\n",
    "# Pipeline for preprocessing combined\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:06:02.155840Z",
     "start_time": "2020-11-17T22:01:23.955384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use preprocessing pipeline to transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T22:09:32.076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B167FC2E18>, <Task finished coro=<f() done, defined at C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_dask.py:316> exception=CommClosedError('in <closed TCP>: Stream is closed',)>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 187, in read\n",
      "    n_frames = await stream.read_bytes(8)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\ioloop.py\", line 779, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_dask.py\", line 317, in f\n",
      "    batch, tasks = await self._to_func_args(func)\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_dask.py\", line 304, in _to_func_args\n",
      "    args = list(await maybe_to_futures(args))\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_dask.py\", line 292, in maybe_to_futures\n",
      "    hash=False\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\client.py\", line 2085, in _scatter\n",
      "    timeout=timeout,\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\core.py\", line 883, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\core.py\", line 666, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 202, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 126, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc)) from exc\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend('dask'):\n",
    "    fsm = LogisticRegression()\n",
    "    fsm.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T22:09:37.066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Score on our training data\n",
    "with joblib.parallel_backend('dask'):\n",
    "    y_pred = fsm.predict(X_train_transformed)\n",
    "    print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T22:09:37.860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Score on our testing data\n",
    "with joblib.parallel_backend('dask'):\n",
    "    y_pred = fsm.predict(X_test_transformed)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T22:09:38.851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "with joblib.parallel_backend('dask'):\n",
    "    plot_confusion_matrix(fsm, X_test_transformed, y_test)\n",
    "    plt.title('FSM')\n",
    "    plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Smote to Deal with Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label -1: {}\".format(sum(y_train == -1))) \n",
    "print(\"Before OverSampling, counts of label 0: {}\".format(sum(y_train == 0))) \n",
    "print(\"Before OverSampling, counts of label 1: {} \\n\".format(sum(y_train == 1))) \n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    # import SMOTE module from imblearn library \n",
    "    # pip install imblearn (if you don't have imblearn in your system) \n",
    "    sm = SMOTE(random_state = 42) \n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_transformed, y_train.ravel()) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "\n",
    "print(\"After OverSampling, counts of label -1: {}\".format(sum(y_train_res == -1))) \n",
    "print(\"After OverSampling, counts of label 0\".format(sum(y_train_res == 0))) \n",
    "print(\"After OverSampling, counts of label 1: {}\".format(sum(y_train_res == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context = 'notebook', style = 'whitegrid')\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,4)) \n",
    "ax1.hist(y, color = 'red', alpha = .5, bins = 5)\n",
    "ax1.set_title('Class distribution before SMOTE')\n",
    "ax2.hist(y_train_res, color = 'blue', alpha = .5, bins = 5)\n",
    "ax2.set_title('Class distribution After SMOTE')\n",
    "fig.tight_layout()\n",
    "plt.savefig('../../reports/figures/Fixing_class_imbalance.jpg', bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
